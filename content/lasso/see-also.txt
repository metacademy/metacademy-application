* Ridge regression is another regularized version of linear regression, using an L2 penalty instead of L1. [ridge-regression]
* The LASSO encourages sparsity of the weight vector. If we believe certain features are likely to be important as a group, we can use group sparsity instead. [group-sparsity]
* Some algorithms for optimizing the LASSO objective include:
** stochastic gradient descent [stochastic-gradient-descent]
** least angle regression (LARS) [lars]
** Fast Iterative Shrinkage-Thresholding Algorithm (FISTA) [fista]
* Other uses of L1 regularization include:
** sparse coding for learning representations [sparse-coding]
** learning sparse undirected graphical models [learning-sparse-undirected-models]
** compressed sensing [compressed sensing]

 
